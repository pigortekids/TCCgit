{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#################################### IMPORTS ###################################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from keras.backend.tensorflow_backend import set_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### INICIALIZACAO DE VARIAVEIS ################################################\n",
    "index_arquivo = ['preco', 'hr_int', 'preco_pon', 'qnt_soma', 'max', 'min', 'IND', 'ISP'] #index do arquivo\n",
    "steps = [] # 9h04 -> 17h50 a cada 5 segundos \n",
    "epocas = 1000 #quantidade de vezes que vai rodar todos os dias\n",
    "janela = 10 #janela de valores\n",
    "n_variaveis = len(index_arquivo) #'preco', 'hr_int', 'preco_pon', 'qnt_soma', 'max', 'min', 'IND', 'ISP'\n",
    "n_entradas = n_variaveis * janela + 2 #ncont, valor, posicao e inputs\n",
    "n_neuronios = 216 #numero de neuronios da camada escondida\n",
    "n_saidas = 3 #nmero de saidas da rede (compra, vende, segura)\n",
    "custo = 1.06/2 #custo da operao\n",
    "melhor_reward = 0\n",
    "lim_cont = 10\n",
    "posicao_max = 100*lim_cont #define variavel para normalizar a posicao\n",
    "\n",
    "versao_arquivo = 1\n",
    "\n",
    "carregar_pesos = False\n",
    "carregar_epoca_epsilon = False\n",
    "epoca_init = 0\n",
    "if carregar_epoca_epsilon:\n",
    "    file = open(\"./epoca_epsilon.txt\", \"r\")\n",
    "    valores = file.read().split(',')\n",
    "    epoca_init = int(valores[0])\n",
    "    epsilon = float(valores[1])\n",
    "    file.close()\n",
    "else:\n",
    "    epsilon = 1. #valor de epsilon\n",
    "epsilon_min = 0.01 #valor minimo de epsilon\n",
    "epsilon_decay = (epsilon - epsilon_min) / (epocas - epoca_init) #o valor que vai retirado do epsilon por epoca\n",
    "\n",
    "rewards = [0] #variavel para guardar rewards\n",
    "plotx = [0] #variavel para guardar valores a serem plotados do eixo x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### LEITURA DOS DADOS #######################################################\n",
    "caminho_arquivo = ('./consolidado.csv')\n",
    "arquivo = pd.read_csv(caminho_arquivo) #le arquivo\n",
    "inputs = arquivo[index_arquivo]\n",
    "if versao_arquivo == 1: #se quiser usar apenas os dias com IND e ISP\n",
    "    inputs = inputs[inputs['IND'] != 0]\n",
    "    arquivo = arquivo[arquivo['IND'] != 0]\n",
    "pmax = np.amax( inputs.loc[:, inputs.columns[0]] ) #define valor minimo do preo\n",
    "pmin = np.amin( inputs.loc[:, inputs.columns[0]] ) #define valor maximo do preo\n",
    "\n",
    "for i in range( inputs.shape[1] ): #roda normalizo para todas as colunas\n",
    "    imax = np.amax( inputs.loc[:, inputs.columns[i]] ) #pega valor maximo\n",
    "    imin = np.amin( inputs.loc[:, inputs.columns[i]] ) #pega valor minimo\n",
    "    inputs.loc[:, inputs.columns[i]] = ( inputs.loc[:, inputs.columns[i]] - imin ) / ( imax - imin ) #normaliza prs\n",
    "\n",
    "dt = arquivo['dt'].values #cria coluna apenas dos dias\n",
    "\n",
    "steps = []\n",
    "ultimo_dia = 0\n",
    "dias_para_rodar = [] #variavel para colocar os dias a serem rodados\n",
    "j = 0\n",
    "hr = []\n",
    "h = 0\n",
    "n_steps = 106 #especifico pra 5min\n",
    "for i in range( 0, len(dt) ):    \n",
    "    if (dt[i] != ultimo_dia):\n",
    "        steps.append(i) #numero de linhas entre dias\n",
    "        ultimo_dia = dt[i]\n",
    "        dias_para_rodar.append(j) #numero do dia\n",
    "        j += 1\n",
    "        h = 0\n",
    "    hr.append(h)\n",
    "    h += 1\n",
    "step_max = np.amax(hr)\n",
    "hr = hr/step_max\n",
    "inputs['hr_int'] = hr\n",
    "\n",
    "\n",
    "dias = len(steps)\n",
    "dias = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               21248     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 192)               49344     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 95,683\n",
      "Trainable params: 95,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "########################################   BIBLIOTECAS ####################################\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K            #importa backend para clear_session()\n",
    "\n",
    "##################### MODELO DQN ####################################################\n",
    "class DQNAgent:\n",
    "    ########################### INICIALIZA ###########################################\n",
    "    def __init__(self, state_size, action_size, epsilon, janela, n_neuronios, n_variaveis):\n",
    "        self.state_size = state_size\n",
    "        self.n_neuronios = n_neuronios\n",
    "        self.action_size = action_size\n",
    "        self.janela = janela\n",
    "        self.n_variaveis = n_variaveis\n",
    "        self.limpa_memoria()\n",
    "        self.gamma = 0.99       # discount rate\n",
    "        self.epsilon = epsilon  # exploration rate\n",
    "        self.learning_rate = 1e-5\n",
    "        self.model = self.cria_modelo()\n",
    "        self.model.summary()\n",
    "        self.state = []\n",
    "        self.next_state = []\n",
    "\n",
    "################################# REDE NEURAL ###########################################\n",
    "    def cria_modelo(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        \"\"\"\n",
    "        model.add(Dense(self.n_neuronios, input_dim=self.state_size, activation='relu')) #camada de entrada (escondida)\n",
    "        model.add(Dense(self.n_neuronios, activation='relu')) #camada escondida\n",
    "        model.add(Dense(self.n_neuronios, activation='relu')) #camada escondida\n",
    "        model.add(Dense(self.action_size, activation='softmax')) #camada de saida\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=tf.train.AdamOptimizer(learning_rate=self.learning_rate)) #compilador\n",
    "        \"\"\"\n",
    "        \n",
    "        model.add(Dense(256, input_dim=self.state_size, activation='relu')) #camada de entrada (escondida)\n",
    "        model.add(Dense(192, activation='relu')) #camada escondida\n",
    "        model.add(Dense(128, activation='relu')) #camada escondida\n",
    "        model.add(Dense(self.action_size, activation='linear')) #camada de saida\n",
    "        model.compile(loss='mse', optimizer=tf.train.AdamOptimizer(learning_rate=self.learning_rate)) #compilador\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def limpa_memoria(self):\n",
    "        self.state = np.empty((0,))\n",
    "        self.next_state = np.empty((0,))\n",
    "        self.memory = []\n",
    "        \n",
    "    def toma_acao(self, valores_ant, teste):\n",
    "        if not teste and np.random.rand() <= self.epsilon: #se o numero aleatorio for menor que o epsilon\n",
    "            return random.randrange(self.action_size) #retorna acao aleatoria\n",
    "        estado = np.array([np.append(self.state, valores_ant)]) #cria valor de agora        \n",
    "        act_values = self.model.predict(estado, batch_size=1) #calcula qual a melhor acao\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "    \n",
    "    def treina_modelo(self, batch_size=step_max):\n",
    "        x = np.zeros((batch_size+1, self.state_size))\n",
    "        y = np.zeros((batch_size+1, self.action_size))\n",
    "        i = 0\n",
    "        for acao, reward, estado, prox_estado, done in self.memory:        \n",
    "            \n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma * np.amax(self.model.predict(prox_estado, batch_size=batch_size)[0])) #pega valor que quer chegar\n",
    "\n",
    "            target_f = self.model.predict(estado, batch_size=batch_size) #pega valor que chegou\n",
    "            target_f[0][acao] = target #define o valor que deseja chegar\n",
    "            x[i,:] = estado\n",
    "            y[i,:] = target_f\n",
    "            i = i + 1\n",
    "            \n",
    "        self.model.fit(x, y, epochs=1, verbose=0, batch_size=batch_size) #treina modelo\n",
    "        \n",
    "    def tira_ultimo_state(self):\n",
    "        if self.state.shape[0] > self.janela * self.n_variaveis:\n",
    "            self.state = self.state[self.n_variaveis:] #tira os ultimos preos\n",
    "        if self.next_state.shape[0] > self.janela * self.n_variaveis:\n",
    "            self.next_state = self.next_state[self.n_variaveis:] #tira os ultimos preos\n",
    "    \n",
    "    def remember(self, acao, reward, valores_ant, valores_dps, done):\n",
    "        prox_estado = np.array([np.append(self.next_state, valores_dps)]) #cria proximo estado\n",
    "        estado = np.array([np.append(self.state, valores_ant)]) #cria valor de agora\n",
    "        self.memory.append((acao, reward, estado, prox_estado, done))\n",
    "    \n",
    "    def carrega_pesos(self, name):\n",
    "        self.model.load_weights(name) #carrega pesos\n",
    "\n",
    "    def salva_pesos(self, name):\n",
    "        self.model.save_weights(name) #salva pesos\n",
    "                \n",
    "########################  DECLARA MODELO ################################\n",
    "modelo = DQNAgent(n_entradas, n_saidas, epsilon, janela, n_neuronios, n_variaveis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### FUNCOES ###############################################################\n",
    "\n",
    "def atuacao( preco, ncont, acao, custo, valor ):  #preo atual, n de contratos posicionados,\n",
    "                                                #acaoo atual, custo, valor da posio\n",
    "    preco_cheio = 0.\n",
    "    valor_cheio = 0.\n",
    "    ncont_anterior = ncont #salva posio anterior\n",
    "    ncont += acao #posio atual = pos anterior + ao\n",
    "    r = 0.\n",
    "        \n",
    "    if acao != 0:\n",
    "        if (acao*ncont_anterior) < 0:    #realizacao (lucro ou prejuizo)\n",
    "            valor_cheio = ( valor * ( pmax - pmin ) + pmin )  #valores nao normalizados\n",
    "            preco_cheio = ( preco * ( pmax - pmin ) + pmin )\n",
    "            r = acao*(valor_cheio - preco_cheio)*10 - custo*abs(acao)  #reward se houve diminuicao da posicao\n",
    "        else:\n",
    "            r = -custo*abs(acao)                                       #reward = -custo*acao se houve operacao\n",
    "        \n",
    "        if valor!=0: \n",
    "            valor_cheio = ( valor * ( pmax - pmin ) + pmin )  #valores nao normalizados\n",
    "        if abs(ncont) > 0:\n",
    "            valor = (ncont_anterior*valor + acao*preco)/ncont     \n",
    "        else:\n",
    "            valor = 0\n",
    "            \n",
    "    if valor!=0: valor_cheio = ( valor * ( pmax - pmin ) + pmin )  #valor posicionado atual\n",
    "            \n",
    "    dp = ( preco * ( pmax - pmin ) + pmin ) - valor_cheio #variacao do preco atual e do preco de compra/venda\n",
    "    posicao = ncont * dp * 10 - custo*abs(ncont)           #posicao = lucro (INSTANTNEO)\n",
    "    \n",
    "    return ncont, valor, posicao, ncont_anterior, r\n",
    "\n",
    "def obter_acao(ncont, valores_ant):\n",
    "    decisao = modelo.toma_acao(valores_ant, False) #calcula a saida da rede neural\n",
    "    \n",
    "    if decisao == 0: #comprar\n",
    "        if ncont < lim_cont: #s compra se no tem nada ainda\n",
    "            return 1\n",
    "    elif decisao == 1: #vender\n",
    "        if ncont > -lim_cont: #sÃ³ vende se tiver alguma coisa\n",
    "            return -1\n",
    "    return 0 #neutro\n",
    "\n",
    "def rodar_1dia(precos, custo, dia):\n",
    "    global melhor_reward\n",
    "    ncont = 0 #cria variavel de quantidade de contratos\n",
    "    ncont_anterior = 0 #cria variavel para quantidade de contratos anterior\n",
    "    valor = 0 #cria variavel para preo medio\n",
    "    reward = 0 #cria variavel para recompensa\n",
    "    posicao = 0 #cria variavel de posio \n",
    "    erro = []\n",
    "    modelo.limpa_memoria() #limpa o vetor de memoria\n",
    "    done = False\n",
    "    modelo.state = np.zeros(n_variaveis*janela)\n",
    "    modelo.next_state = np.zeros(n_variaveis*janela)\n",
    "    \n",
    "    for step in range( steps[dia - 1], steps[dia] ):  #roda os dados\n",
    "        \n",
    "        ultimos_precos = precos[ step : step + 1 ] #pega os valores de agora\n",
    "        modelo.state = np.append( modelo.state, ultimos_precos ) #adiciona na variavel de estado\n",
    "        \n",
    "        modelo.tira_ultimo_state()\n",
    "        valores_ant = [ncont / lim_cont, valor] #grava os valores de antes - estado\n",
    "\n",
    "        acao = obter_acao( ncont, valores_ant ) #obtem acao\n",
    "        ncont, valor, posicao, ncont_anterior, r = atuacao(precos['preco'][step], ncont, acao, custo, valor)\n",
    "        reward += r\n",
    "        #print (hr[step]*step_max, acao)\n",
    "        #print(\"acao: {0} reward: {1} step: {2}\".format(acao, reward, hr[step]*step_max))\n",
    "            \n",
    "        prox_precos = precos[ step + 1 : step + 2 ] #pega os proximos valores\n",
    "        modelo.next_state = np.append(modelo.next_state, prox_precos) #adiciona variavel na variavel de proximo estado\n",
    "        modelo.tira_ultimo_state()\n",
    "        valores_dps = [ncont / lim_cont, valor] #grava os valores de depois\n",
    "        \n",
    "        if step == (steps[dia] - 1):\n",
    "            done = True\n",
    "        \n",
    "        modelo.remember(acao, posicao + reward, valores_ant, valores_dps, done)  #salva step na memoria\n",
    "    \n",
    "    reward += posicao - custo * abs(ncont) #soma reward - DAY-TRADE (obs: custo nao havia sido considerado no reward pq acao era 0)\n",
    "    \n",
    "    modelo.treina_modelo() #roda o modelo com toda a memoria do dia\n",
    "           \n",
    "    if reward > melhor_reward:\n",
    "        melhor_reward = reward\n",
    "    return reward #retorna o valor do reward\n",
    "\n",
    "dias_pos = 0\n",
    "dias_neg = 0\n",
    "\n",
    "def rodar_dias(precos, custo):   \n",
    "    global dias_pos\n",
    "    global dias_neg\n",
    "    sum_rewards = 0 #cria variavel de somatoria de recompensas\n",
    "    for dia in range( 1, dias ): #loop de dias\n",
    "        reward = rodar_1dia(precos, custo, dia)\n",
    "        sum_rewards += reward #roda 1 dia e adiciona o total na variavel de somatoria\n",
    "        #print(\"dia {0} de {1}: R$ {2:0.2f}\".format(dia, dias, reward)) #mostra o resultado do dia\n",
    "        if reward>0: \n",
    "            dias_pos += 1\n",
    "        elif reward<0:\n",
    "            dias_neg += 1\n",
    "    return sum_rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1018 21:04:43.280857 10200 deprecation_wrapper.py:119] From C:\\Users\\core\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W1018 21:04:44.540540 10200 deprecation_wrapper.py:119] From C:\\Users\\core\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "W1018 21:04:44.672504 10200 deprecation_wrapper.py:119] From C:\\Users\\core\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultado da epoca 0 = -58230.02\n",
      "47\n",
      "52\n",
      "resultado da epoca 1 = 68644.05\n",
      "54\n",
      "45\n",
      "resultado da epoca 2 = 19191.68\n",
      "50\n",
      "49\n",
      "resultado da epoca 3 = -12134.34\n",
      "50\n",
      "49\n",
      "resultado da epoca 4 = -69182.36\n",
      "36\n",
      "63\n",
      "resultado da epoca 5 = -58217.03\n",
      "41\n",
      "58\n",
      "resultado da epoca 6 = 42678.96\n",
      "52\n",
      "47\n",
      "resultado da epoca 7 = -93220.29\n",
      "43\n",
      "56\n",
      "resultado da epoca 8 = -84774.44\n",
      "43\n",
      "56\n",
      "resultado da epoca 9 = -13632.33\n",
      "46\n",
      "53\n",
      "resultado da epoca 10 = -58549.97\n",
      "42\n",
      "57\n",
      "resultado da epoca 11 = -65175.75\n",
      "42\n",
      "57\n",
      "resultado da epoca 12 = -30930.22\n",
      "42\n",
      "57\n",
      "resultado da epoca 13 = -51755.19\n",
      "41\n",
      "58\n",
      "resultado da epoca 14 = -31553.00\n",
      "44\n",
      "55\n",
      "resultado da epoca 15 = -59213.96\n",
      "42\n",
      "57\n",
      "resultado da epoca 16 = -104365.08\n",
      "42\n",
      "57\n",
      "resultado da epoca 17 = -85179.96\n",
      "37\n",
      "62\n",
      "resultado da epoca 18 = -39480.20\n",
      "50\n",
      "49\n",
      "resultado da epoca 19 = -45349.30\n",
      "40\n",
      "59\n",
      "resultado da epoca 20 = -57147.75\n",
      "43\n",
      "56\n",
      "resultado da epoca 21 = -57994.03\n",
      "44\n",
      "55\n",
      "resultado da epoca 22 = -60370.24\n",
      "42\n",
      "57\n",
      "resultado da epoca 23 = -54942.49\n",
      "43\n",
      "56\n",
      "resultado da epoca 24 = -41556.65\n",
      "42\n",
      "57\n",
      "resultado da epoca 25 = -50398.05\n",
      "45\n",
      "54\n",
      "resultado da epoca 26 = -54301.61\n",
      "43\n",
      "56\n",
      "resultado da epoca 27 = -58133.54\n",
      "43\n",
      "56\n",
      "resultado da epoca 28 = -57801.98\n",
      "41\n",
      "58\n",
      "resultado da epoca 29 = -50581.89\n",
      "40\n",
      "59\n",
      "resultado da epoca 30 = -43017.36\n",
      "43\n",
      "56\n",
      "resultado da epoca 31 = -50531.37\n",
      "39\n",
      "60\n",
      "resultado da epoca 32 = -34554.89\n",
      "47\n",
      "52\n",
      "resultado da epoca 33 = -44191.99\n",
      "42\n",
      "57\n",
      "resultado da epoca 34 = -44345.44\n",
      "41\n",
      "58\n",
      "resultado da epoca 35 = -19135.99\n",
      "43\n",
      "56\n",
      "resultado da epoca 36 = -35752.30\n",
      "42\n",
      "57\n",
      "resultado da epoca 37 = -17936.13\n",
      "40\n",
      "59\n",
      "resultado da epoca 38 = -40492.77\n",
      "41\n",
      "58\n",
      "resultado da epoca 39 = -26153.15\n",
      "40\n",
      "59\n",
      "resultado da epoca 40 = -31499.35\n",
      "45\n",
      "54\n",
      "resultado da epoca 41 = -41963.73\n",
      "43\n",
      "56\n",
      "resultado da epoca 42 = -35223.95\n",
      "44\n",
      "55\n",
      "resultado da epoca 43 = -31730.27\n",
      "44\n",
      "55\n",
      "resultado da epoca 44 = -31356.06\n",
      "41\n",
      "58\n",
      "resultado da epoca 45 = -40646.52\n",
      "42\n",
      "57\n",
      "resultado da epoca 46 = -30939.63\n",
      "44\n",
      "55\n",
      "resultado da epoca 47 = -15338.66\n",
      "43\n",
      "56\n",
      "resultado da epoca 48 = -21250.80\n",
      "44\n",
      "55\n",
      "resultado da epoca 49 = -23955.43\n",
      "43\n",
      "56\n",
      "resultado da epoca 50 = -21794.10\n",
      "43\n",
      "56\n",
      "resultado da epoca 51 = -21794.10\n",
      "43\n",
      "56\n",
      "resultado da epoca 52 = -21794.10\n",
      "43\n",
      "56\n",
      "resultado da epoca 53 = -21794.10\n",
      "43\n",
      "56\n",
      "resultado da epoca 54 = -21794.10\n",
      "43\n",
      "56\n",
      "resultado da epoca 55 = -21794.10\n",
      "43\n",
      "56\n",
      "resultado da epoca 56 = -21794.10\n",
      "43\n",
      "56\n",
      "resultado da epoca 57 = -21794.10\n",
      "43\n",
      "56\n",
      "resultado da epoca 58 = -21794.10\n",
      "43\n",
      "56\n",
      "resultado da epoca 59 = -21794.10\n",
      "43\n",
      "56\n",
      "resultado da epoca 60 = -21794.10\n",
      "43\n",
      "56\n",
      "resultado da epoca 61 = -21794.10\n",
      "43\n",
      "56\n",
      "resultado da epoca 62 = -21794.10\n",
      "43\n",
      "56\n",
      "resultado da epoca 63 = -21794.10\n",
      "43\n",
      "56\n",
      "resultado da epoca 64 = -21794.10\n",
      "43\n",
      "56\n",
      "15\n",
      "20\n",
      "Somatoria dos rewards: -2360584.30\n",
      "Melhor resultado diario: 25871.73\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-987c5ceebc1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoca\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoca_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepocas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#rodar uma quantidade de epocas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;31m#s=time.time()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0msum_rewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrodar_dias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcusto\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#adiciona o resultado da epoca na somatoria\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0msum_rewards_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msum_rewards\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_rewards\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-7ea42d55e942>\u001b[0m in \u001b[0;36mrodar_dias\u001b[1;34m(precos, custo)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0msum_rewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;31m#cria variavel de somatoria de recompensas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdia\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdias\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#loop de dias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrodar_1dia\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcusto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdia\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0msum_rewards\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;31m#roda 1 dia e adiciona o total na variavel de somatoria\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;31m#print(\"dia {0} de {1}: R$ {2:0.2f}\".format(dia, dias, reward)) #mostra o resultado do dia\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-7ea42d55e942>\u001b[0m in \u001b[0;36mrodar_1dia\u001b[1;34m(precos, custo, dia)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mvalores_ant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mncont\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlim_cont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#grava os valores de antes - estado\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0macao\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobter_acao\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mncont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalores_ant\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;31m#obtem acao\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[0mncont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposicao\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncont_anterior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0matuacao\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'preco'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macao\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcusto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mreward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-7ea42d55e942>\u001b[0m in \u001b[0;36mobter_acao\u001b[1;34m(ncont, valores_ant)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mobter_acao\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mncont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalores_ant\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mdecisao\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoma_acao\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalores_ant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#calcula a saida da rede neural\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdecisao\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#comprar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-52cfef264ac9>\u001b[0m in \u001b[0;36mtoma_acao\u001b[1;34m(self, valores_ant, teste)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#retorna acao aleatoria\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mestado\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalores_ant\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#cria valor de agora\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mact_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestado\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#calcula qual a melhor acao\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mact_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# returns action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1462\u001b[1;33m                                             callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "##################################  MAIN  #########################################\n",
    "if __name__ == \"__main__\":\n",
    "    global dias_pos\n",
    "    global dias_neg\n",
    "    sum_rewards_total = 0\n",
    "    #modelo.epsilon = 0.1\n",
    "    sr=[]\n",
    "    try:\n",
    "        if carregar_pesos:\n",
    "            modelo.carrega_pesos('./pesos.h5')\n",
    "        epoca_parou = epoca_init\n",
    "        for epoca in range(epoca_init, epocas): #rodar uma quantidade de epocas\n",
    "            #s=time.time()\n",
    "            sum_rewards = rodar_dias(inputs, custo) #adiciona o resultado da epoca na somatoria\n",
    "            sum_rewards_total += sum_rewards\n",
    "            sr.append(sum_rewards)\n",
    "            print(\"resultado da epoca {0} = {1:0.2f}\".format(epoca, sum_rewards))\n",
    "            print(dias_pos)\n",
    "            print(dias_neg)\n",
    "            epoca_parou += 1\n",
    "            if ((epoca % 200) == 0):\n",
    "                modelo.salva_pesos('./pesos_1.h5')\n",
    "            dias_pos = 0\n",
    "            dias_neg = 0\n",
    "            #e=time.time()\n",
    "            #print(e-s)\n",
    "            modelo.epsilon -= epsilon_decay\n",
    "    finally:\n",
    "        print(dias_pos)\n",
    "        print(dias_neg)\n",
    "        modelo.salva_pesos('./pesos_1.h5')\n",
    "        if carregar_epoca_epsilon:\n",
    "            file = open(\"./epoca_epsilon.txt\", \"w\")\n",
    "            file.writelines(\"{0},{1}\".format(epoca_parou, modelo.epsilon))\n",
    "            file.close()\n",
    "            print(\"parou na epoca {0} com epsilon {1}\".format(epoca_parou, modelo.epsilon))\n",
    "        print(\"Somatoria dos rewards: {0:0.2f}\".format(sum_rewards_total))\n",
    "        print(\"Melhor resultado diario: {0:0.2f}\".format(melhor_reward))\n",
    "        plt.plot(range(0, len(sr)), sr, range(0, len(sr)), np.zeros(len(sr))) #plota os v1alores de reward por epoca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modelo.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hr[0:106])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs['hr_int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hr[0:106])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modelo.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modelo.state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
